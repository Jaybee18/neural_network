from math import exp
from random import random

def sigmoid_d( x ):
    return x * (1 - x)

class Neuron():
    def __init__(self, amountOfInputs, bias):
        self.weights = [random() for i in range(amountOfInputs)]
        self.weight_bias = random()
        self.bias = bias

    def calculateOutput( self , inputs):
        res = 0 + self.bias * self.weight_bias  # = self.weight_bias
        for i in range(len(inputs)):
            res += inputs[i] * self.weights[i]
        return self.sigmoid(res)

    def sigmoid( self , x):
        return 1 / (1 + exp(-x))

    def getWeightAtIndex( self , index):
        return self.weights[index]

    def adjustWeightAtIndex( self , index, delta):
        self.weights[index] += delta

    def adjustBiasWeight( self , delta):
        self.weight_bias += delta

    def getTotalNumberOfWeights( self ):
        return len(self.weights)

class NeuronLayer():
    def __init__(self, amountOfInputs, amountOfNeurons):
        self.bias = 1
        self.neurons = [Neuron(amountOfInputs, self.bias) for i in range(amountOfNeurons)]
        self.weight_d = [[[] for j in range(amountOfInputs)] for i in range(len(self.neurons))]
        self.lastinputs = None

    def calculateOutput( self , inputs):
        self.lastinputs = inputs
        outputs = []
        for neuron in self.neurons:
            outputs.append(neuron.calculateOutput(inputs))
        return outputs

    def adjustWeights( self , neuronIndex, weightIndex, delta):
        self.neurons[neuronIndex].adjustWeightAtIndex(weightIndex, delta)

    def getNeruonAtIndex( self , index):
        return self.neurons[index]

    def getTotalNumberOfNeurons( self ):
        return len(self.neurons)

    def addWeightDelta( self , neuronIndex, weightIndex, delta):
        self.weight_d[neuronIndex][weightIndex].append(delta)

    def getWeightDelta( self , neuronIndex, weightIndex, index):
        return self.weight_d[neuronIndex][weightIndex][index]

    def getWeights( self ):
        res = []
        for neuronIndex in range(self.getTotalNumberOfNeurons()):
            res.append([])
            for weightIndex in range(self.getNeruonAtIndex(neuronIndex).getTotalNumberOfWeights()):
                res[-1].append(self.getNeruonAtIndex(neuronIndex).getWeightAtIndex(weightIndex))
        return res

    def getLastInputs( self ):
        return self.lastinputs


class NeuralNetwork():
    def __init__(self, amountOfInputs, hiddenlayers, outputlayerNeurons):
        lastLayerNeurons = amountOfInputs
        self.hidden = []
        for hiddenlayerArchitecture in range(len(hiddenlayers)):
            self.hidden.append(NeuronLayer(lastLayerNeurons, hiddenlayers[hiddenlayerArchitecture]))
            lastLayerNeurons = hiddenlayers[hiddenlayerArchitecture]
        self.outputlayer = NeuronLayer(lastLayerNeurons, outputlayerNeurons)

    def getWeights( self ):
        res = [self.hidden[i].getWeights() for i in range(len(self.hidden))]
        res.append(self.outputlayer.getWeights())
        return res

    def predict( self , inputs):
        lastlayeroutput = inputs
        for hiddenlayer in self.hidden:
            lastlayeroutput = hiddenlayer.calculateOutput(lastlayeroutput)
        out = self.outputlayer.calculateOutput(lastlayeroutput)
        return out

    def train( self , inputs, outputs, learningrate=0.5, iterations=100_000):
        for j in range(iterations):
            hl_weight_deltas = [[[[] for index2 in range(hiddenlayer.getNeruonAtIndex(index).getTotalNumberOfWeights())] for index in range(hiddenlayer.getTotalNumberOfNeurons())] for hiddenlayer in self.hidden]
            ol_weight_deltas = [[[] for index2 in range(self.outputlayer.getNeruonAtIndex(index).getTotalNumberOfWeights())] for index in range(self.outputlayer.getTotalNumberOfNeurons())]
            for i in range(len(inputs)):
                # forward pass
                out_h = []
                lastoutput = inputs[i]
                for hiddenlayer in self.hidden:
                    out_h.append(hiddenlayer.calculateOutput(lastoutput))
                    lastoutput = out_h[-1]
                if out_h == []:
                    out_h = [inputs[i]]
                out_o = self.outputlayer.calculateOutput(lastoutput)

                error = [outputs[i][neuronIndex] - out_o[neuronIndex] for neuronIndex in range(self.outputlayer.getTotalNumberOfNeurons())]

                # calculate the deltas for the weights that are connected to the output layer
                # ∂e/∂w = ∂e/∂a * ∂a/∂z * ∂z/∂w ( * learningrate )
                # where:
                # e is the totalError,
                # w is the weight,
                # a is the activation (the output of the neuron)
                # z is the netInput
                o_deltas = [ [ ] for index in range( self.outputlayer.getTotalNumberOfNeurons() ) ]
                for neuronIndex in range( self.outputlayer.getTotalNumberOfNeurons() ):
                    for weightIndex in range( self.outputlayer.getNeruonAtIndex( neuronIndex ).getTotalNumberOfWeights() ):
                        # ∂e/∂z = ∂e/∂a * ∂a/∂z                     [1]
                        o_deltas[ neuronIndex ].append( error[ neuronIndex ] * sigmoid_d( out_o[ neuronIndex ] ) )
                        # ∂e/∂w = ∂e/∂z * ∂z/∂w ( * learningrate )
                        ol_weight_deltas[neuronIndex][weightIndex].append(o_deltas[neuronIndex][weightIndex] * out_h[-1][weightIndex] * learningrate)
                    # the bias weight is updated like this:
                    # ∂e/∂b = ∂e/∂a * ∂a/∂z * ∂z/∂b ( * learningrate )
                    #       = ∂e/∂z * ∂z/∂b ( * learningrate )
                    #       = ∂e/∂z ( * learningrate )  | since "∂z/∂b" is always 1
                    # and it is updated instantly, because it isn't used anymore
                    # in further calculations
                    self.outputlayer.getNeruonAtIndex(neuronIndex).adjustBiasWeight(o_deltas[neuronIndex][0] * 1 * learningrate)

                # calculate the deltas for the hidden layers
                # ∂e/∂w = ∂e/∂a_h * ∂a/∂z * ∂z/∂w ( * learningrate )
                # ∂e/∂a_h = ∂e/∂a_o1 + ... + ∂e/∂a_oN
                beforeLayer = self.outputlayer
                beforeDeltas = o_deltas
                for hiddenlayerIndex in reversed(range(len(self.hidden))):
                    h_current_weights = self.hidden[hiddenlayerIndex].getWeights()
                    h_deltas = [[0 for index2 in range(len(h_current_weights[0]))] for index in range(len(h_current_weights))]
                    for h_neuronIndex in range( self.hidden[hiddenlayerIndex].getTotalNumberOfNeurons() ):
                        # tempSum is the totalError wrt the activation of the current hiddenlayerneuron
                        # ∂e/∂a_h = ∂e/∂a_o1 + ... + ∂e/∂a_oN
                        # ∂e/∂a_o1 = ∂e/a_o1 * ∂a_o1/∂z_o1 * ∂z_o1/∂a_h
                        #           |_____________________|     ||
                        #                      \/               ||
                        # this was computed before (comment in line 124 [1]) so we can just reuse it
                        #                                       ||
                        #                                       \/
                        # and this is just the weight connecting that previous
                        # layer neuron to the current hiddenlayer neuron
                        tempSum = 0
                        for o_neuronIndex in range( beforeLayer.getTotalNumberOfNeurons() ):
                            tempSum += beforeDeltas[ o_neuronIndex ][ h_neuronIndex ] * beforeLayer.getNeruonAtIndex( o_neuronIndex ).getWeightAtIndex( h_neuronIndex )
                        # save the weight deltas in a list to update later
                        for weightIndex in range( len( h_deltas[ h_neuronIndex ] ) ):
                            # ∂e/∂z = ∂e/∂a * ∂a/∂z
                            h_deltas[ h_neuronIndex ][ weightIndex ] = tempSum * sigmoid_d( out_h[hiddenlayerIndex][ h_neuronIndex ] )
                            # ∂e/∂w = ∂e/∂z * ∂z/∂w ( * learningrate )
                            hl_weight_deltas[hiddenlayerIndex][ h_neuronIndex ][ weightIndex ].append(h_deltas[ h_neuronIndex ][ weightIndex ] * self.hidden[hiddenlayerIndex].getLastInputs()[ weightIndex ] * learningrate )
                        # ∂e/∂b = ∂e/∂a * ∂a/∂z * ∂z/∂b ( * learningrate )
                        self.hidden[hiddenlayerIndex].getNeruonAtIndex(h_neuronIndex).adjustBiasWeight(h_deltas[h_neuronIndex][0] * 1 * learningrate)
                    beforeLayer = self.hidden[hiddenlayerIndex]
                    beforeDeltas = h_deltas

            # update all the weights with the saved weight deltas
            for neuronIndex in range( self.outputlayer.getTotalNumberOfNeurons() ):
                for weightIndex in range( self.outputlayer.getNeruonAtIndex( neuronIndex ).getTotalNumberOfWeights() ):
                    for d in ol_weight_deltas[ neuronIndex ][ weightIndex ]:
                        self.outputlayer.adjustWeights( neuronIndex, weightIndex, d )
            for hiddenlayerIndex in range(len(self.hidden)):
                for neuronIndex in range( self.hidden[hiddenlayerIndex].getTotalNumberOfNeurons() ):
                    for weightIndex in range( self.hidden[hiddenlayerIndex].getNeruonAtIndex( neuronIndex ).getTotalNumberOfWeights() ):
                        for d in hl_weight_deltas[hiddenlayerIndex][ neuronIndex ][ weightIndex ]:
                            self.hidden[hiddenlayerIndex].adjustWeights( neuronIndex, weightIndex, d )



if __name__ == '__main__':
    input = [[1, 1], [0, 1], [1, 0], [0, 0]]
    target = [[0], [1], [1], [0]]

    n = NeuralNetwork(2, [2], 1)
    print(n.predict(input[0]))
    n.train(input, target)
    print('')
    for i in input:
        print(n.predict(i))
